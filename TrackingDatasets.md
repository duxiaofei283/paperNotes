## Tracking Datasets

### 2D Single Object Tracking (SOT)

- [**VOT Challenges (2013-2017)**](http://www.votchallenge.net/index.html)

  > The VOT challenges provide the visual tracking community with a precisely defined and repeatable way of comparing short-term trackers as well as a common platform for discussing the evaluation and advancements made in the field of visual tracking.

- [**Visual Tracker Benchmark (OBT)**](http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html)

  > The full benchmark contains 100 sequences from recent literatures and code of the benchmark evaluation of online visual tracking algorithms..

  - **Online Object Tracking: A Benchmark.** Yi Wu, Jongwoo Lim and Ming-Hsuan Yang. CVPR (2013). \[[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr13_benchmark.pdf)\]
  - **Ojbect Tracking Benchmark.** Yi Wu, Jongwoo Lim and Ming-Hsuan Yang. PAMI (2015). \[[paper](http://faculty.ucmerced.edu/mhyang/papers/pami15_tracking_benchmark.pdf)\] 



### 2D Multiple Ojbect Tracking (MOT)

- [**EPFL Dataset (2008)**](http://cvlab.epfl.ch/data/pom/#terrace)

  > Multi-camera Pedestrian Videos: All of the sequences feature several synchronised video streams filming the same area under different angles.

- [**ETHZ Sequences (2008)**](https://data.vision.ee.ethz.ch/cvl/aess/dataset/) 

  > Robust Multi-Person Tracking from Mobile Platforms

- [**TUD Datasets (2010)**](https://www.d2.mpi-inf.mpg.de/node/428)

  > The dataset "TUD Multiview Pedestrians" was used to evaluate single-frame people detection and viewpoint estimation. The "TUD Stadmitte" sequence was used to demonstrate 3D pose estimation performance in real-world street conditions.

- [**KITTI Ojbect Tracking (2012)**](http://www.cvlibs.net/datasets/kitti/eval_tracking.php)

  > The object tracking benchmark consists of 21 training sequences and 29 test sequences. The goal in the object tracking task is to estimate object tracklets for the classes 'Car' and 'Pedestrian'.	
  - **Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite.** Andreas Geiger, Philip Lenz and Raquel Urtasun. CVPR (2012). \[[paper](http://www.cvlibs.net/publications/Geiger2012CVPR.pdf)\]

- [**MOT Benchmark (2015-2017)**](https://motchallenge.net/)

  > This benchmark contains video sequences in unconstrained environments filmed with both static and moving cameras.

  - **MOTChallenge 2015: Towards a Benchmark for Multi-Object Tracking.** Laura Leal-Taixé, Anton Milan, Ian Reid, Stefan Roth, and Konrad Schindler. arXiv (2015). [[paper](https://arxiv.org/abs/1504.01942)\]
  - **MOT16: A Benchmark for Multi-Object Tracking.** Anton Milan, Laura Leal-Taixé, Ian Reid, Stefan Roth, and Konrad Schindler. arXiv (2016). [[paper](https://arxiv.org/abs/1603.00831)\]

- [**DukeMTMCT (2016)**](https://motchallenge.net/data/DukeMTMCT/)

  > This dataset is a new, manually annotated, calibrated, multi-camera data set recorded outdoors on the Duke University campus with 8 synchronized cameras.

  - **Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking.** Ergys Ristani, Francesco Solera, Roger S. Zou, Rita Cucchiara, and Carlo Tomasi. arXiv (2016). \[[paper](https://arxiv.org/abs/1609.01775)\]

- [**PETS (2009-2017)**](https://motchallenge.net/data/PETS2017/)

  > Low-density detection, tracking and video analysis.

  - **PETS 2014: Dataset and Challenge.** Luis Patino and James Ferryman. AVSS (2014). \[[paper](http://ieeexplore.ieee.org/document/6918694/)\]\[[dataLink](http://www.cvg.reading.ac.uk/PETS2014/)\]
  - **PETS 2016: Dataset and Challenge.** Longzhen Li, Tahir Nawaz and James Ferryman. AVSS (2015). \[[paper](http://ieeexplore.ieee.org/document/7301741/)\]\[[dataLink](http://www.cvg.reading.ac.uk/PETS2015/)\]
  - **PETS 2016: Dataset and Challenge.** Luis Patino, Tom Cane, Alain Vallee and James Ferryman. CVPR (2016). \[[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w20/papers/Patino_PETS_2016_Dataset_CVPR_2016_paper.pdf)\]\[[dataLink](http://www.cvg.reading.ac.uk/PETS2016/)\]



### 2D Pose

- [**PoseTrack (2017)**](https://posetrack.net/)

  > PoseTrack is a new large-scale benchmark for multi human pose estimation and tracking in video. We provide a publicly available training and validation set as well as an evaluation server for benchmarking on a held-out test set.

- [**Human Skeletal System Keypoints Detection (2017)**](https://challenger.ai/competition/keypoint?lan=en)

### 3D MOT

- [**MOT Benchmark (2015)**](https://motchallenge.net/data/3D_MOT_2015/)

  > This benchmark contains video sequences with available camera calibration, enabling tracking in world coordinates.

- [**WILDTRACK**](http://cvlab.epfl.ch/data/wildtrack) \[[paper](https://arxiv.org/abs/1707.09299)\]

  > The dataset brings multi-camera detection and tracking methods into the wild. It meets the need of the deep learning methods for a large-scale multi-camera dataset of walking pedestrians, where the cameras’ fields of view in large part overlap. Its high precision joint calibration and synchronization shall allow for development of new algorithms that go beyond what is possible with currently available data-sets.


### 3D Pose

- [**TUD Datasets (2010)**](https://www.d2.mpi-inf.mpg.de/node/428)

  > The "TUD Stadmitte" sequence was used to demonstrate 3D pose estimation performance in real-world street conditions.

### Highlights

- [**Institute of Computer Graphics and Vision at TU Graz**](https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/)
- [**Computer Vision Group at RWTH Aachen University **](https://www.vision.rwth-aachen.de/)

